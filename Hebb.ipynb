{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
     "# Hebbian Learning â€” AND Gate\n",
     "This notebook trains a neural unit using **Hebb Learning Rule** and visualizes weight updates after each iteration."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
     "import numpy as np\n",
     "import matplotlib.pyplot as plt"
   ]
  },

  {
   "cell_type": "markdown",
   "source": [
     "### Activation Function"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
     "def activation(x):\n",
     "    return 1 if x >= 0 else -1"
   ]
  },

  {
   "cell_type": "markdown",
   "source": [
     "### Hebbian Training Function with Plot"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
      "def hebb_train_and_plot(inputs, targets):\n",
      "    weights = np.ones(len(inputs[0]) + 1)  # Initialize weights + bias\n",
      "\n",
      "    for i, (x, t) in enumerate(zip(inputs, targets)):\n",
      "        x = np.array([1] + list(x))  # include bias\n",
      "        y_in = np.dot(weights, x)\n",
      "        y_pred = activation(y_in)\n",
      "        weights += t * x  # Hebbian update\n",
      "\n",
      "        # Plotting decision boundary for each step\n",
      "        plt.figure(figsize=(5,5))\n",
      "        for inp, lab in zip(inputs, targets):\n",
      "            color = 'blue' if lab == 1 else 'red'\n",
      "            plt.scatter(inp[0], inp[1], color=color)\n",
      "\n",
      "        x_vals = np.linspace(-2, 2, 100)\n",
      "        if weights[2] != 0:\n",
      "            y_vals = -(weights[1] * x_vals + weights[0]) / weights[2]\n",
      "            plt.plot(x_vals, y_vals)\n",
      "\n",
      "        plt.title(f\"Iteration {i+1}: Updated Weights: {weights}\")\n",
      "        plt.grid()\n",
      "        plt.show()\n",
      "\n",
      "    return weights"
   ]
  },

  {
   "cell_type": "markdown",
   "source": [
     "### AND Gate Dataset (Polar Format)"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
     "inputs  = [(1,1), (1,-1), (-1,1), (-1,-1)]\n",
     "targets = [1, -1, -1, -1]"
   ]
  },

  {
   "cell_type": "markdown",
   "source": [
     "### Train"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
     "final_weights = hebb_train_and_plot(inputs, targets)\n",
     "print(\"Final Weights:\", final_weights)"
   ]
  },

  {
   "cell_type": "markdown",
   "source": [
     "### Test Results"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
     "for x in inputs:\n",
     "    x_b = np.array([1] + list(x))\n",
     "    y = activation(np.dot(final_weights, x_b))\n",
     "    print(f\"Input: {x} -> Output: {y}\")"
   ]
  }
 ]
}
