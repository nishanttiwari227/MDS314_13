{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138a5e9e",
   "metadata": {},
   "source": [
    "\n",
    "# Hebbian Learning â€” AND Gate (ready-to-upload `.ipynb`)\n",
    "\n",
    "This notebook trains a simple Hebbian perceptron on the bipolar AND gate and shows plots and outputs\n",
    "embedded in the notebook so GitHub will preview them (images + text output).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0841a8ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python (venv) (Python 3.11.9)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def activation_function(x):\n",
    "    return 1 if x >= 0 else -1\n",
    "\n",
    "def hebb_train(inputs, targets, init_weights=None):\n",
    "    n_features = inputs.shape[1]\n",
    "    if init_weights is None:\n",
    "        weights = np.ones(n_features + 1, dtype=float)\n",
    "    else:\n",
    "        weights = init_weights.astype(float).copy()\n",
    "    for x, y in zip(inputs, targets):\n",
    "        x_aug = np.array([1.0] + list(x))\n",
    "        weights = weights + y * x_aug\n",
    "    return weights\n",
    "\n",
    "def predict(weights, x):\n",
    "    x_aug = np.array([1.0] + list(x))\n",
    "    net = np.dot(weights, x_aug)\n",
    "    return activation_function(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: bipolar AND gate\n",
    "inputs = np.array([[1,1],[1,-1],[-1,1],[-1,-1]], dtype=float)\n",
    "targets = np.array([1, -1, -1, -1], dtype=float)\n",
    "\n",
    "weights_init = np.ones(inputs.shape[1] + 1, dtype=float)\n",
    "weights_final = hebb_train(inputs, targets, init_weights=weights_init)\n",
    "\n",
    "print('Initial weights:', weights_init)\n",
    "print('Final weights after Hebbian training:', weights_final)\n",
    "print('\\nPredictions on training set:')\n",
    "for x in inputs:\n",
    "    print(' Input', list(x), '->', predict(weights_final, x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d0e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function plot (image embedded below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84efc20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision boundary BEFORE training (image embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision boundary AFTER training (image embedded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
